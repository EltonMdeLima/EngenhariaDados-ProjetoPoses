# Projeto de Engenharia de Dados: Pipeline DataOps para AnÃ¡lise de Poses ğŸ¤–ğŸ“ŠğŸ¥

![Conceito de Imagem de Alto NÃ­vel](https://i.imgur.com/your_image_placeholder.png) 
*Substitua este placeholder com um link para a imagem conceitual descrita acima, se for criada.*

Este projeto foi desenvolvido como parte das atividades do curso de **Especialista em DevOps**, com um foco em **Engenharia de Dados**. Ele exemplifica a construÃ§Ã£o de um pipeline, automatizado e containerizado para a anÃ¡lise e estruturaÃ§Ã£o de movimentos humanos a partir de vÃ­deos.

## 1. VisÃ£o Geral do Projeto

A anÃ¡lise de movimentos humanos, como esportes (otimizaÃ§Ã£o de performance), fisioterapia (reabilitaÃ§Ã£o e acompanhamento), e animaÃ§Ã£o 3D (automaÃ§Ã£o da criaÃ§Ã£o de personagens). Tradicionalmente, a extraÃ§Ã£o de **pontos-chave (keypoints)** que definem a pose de uma pessoa em vÃ­deos Ã© um processo complexo e trabalhoso, exigindo um roupa especial com sensores para capturar movimentos, propenso a erros, demorado e que resulta em dados nÃ£o estruturados, dificultando anÃ¡lises em escala e automaÃ§Ã£o.

Este projeto propÃµe uma soluÃ§Ã£o para esse desafio. A construÃ§Ã£o de pipeline de dados que automatiza a ingestÃ£o de vÃ­deos, a extraÃ§Ã£o de keypoints atravÃ©s de inteligÃªncia artificial, a transformaÃ§Ã£o desses dados em um formato estruturado e o armazenamento em um banco de dados relacional local (SQLite). O tratamento desses dados e a preparaÃ§Ã£o dos keypoints limpos e disponibilizados em arquivos JSON, prontos para integraÃ§Ã£o com ferramentas de modelagem 3D como o Blender, que suportam scripts Python para automaÃ§Ã£o de animaÃ§Ãµes.

## 2. Objetivos do Projeto

O principal objetivo Ã© demonstrar a aplicaÃ§Ã£o de princÃ­pios de Engenharia de Dados e DevOps na criaÃ§Ã£o de um sistema eficiente e reproduzÃ­vel para anÃ¡lise de movimentos. Os objetivos especÃ­ficos incluem:

*   **AutomaÃ§Ã£o da ExtraÃ§Ã£o:** Automatizar a detecÃ§Ã£o e extraÃ§Ã£o de 33 keypoints de pose humana por frame de vÃ­deos de entrada.
*   **EstruturaÃ§Ã£o de Dados:** Transformar os dados semi-estruturados (JSON) gerados pela IA em um formato tabular otimizado para anÃ¡lise.
*   **Armazenamento Eficiente:** Persistir os dados brutos (JSON) e estruturados (SQLite) de forma organizada.
*   **ContainerizaÃ§Ã£o:** Envelopar todo o ambiente e pipeline em contÃªineres Docker, garantindo portabilidade e reprodutibilidade.
*   **PrÃ¡ticas DataOps/DevOps:** Implementar Infraestrutura como CÃ³digo (IaC) e um fluxo de trabalho que promova a colaboraÃ§Ã£o e a entrega contÃ­nua.
*   **PreparaÃ§Ã£o para AnimaÃ§Ã£o 3D:** Gerar dados em um formato que possa ser facilmente consumido por ferramentas de modelagem 3D, facilitando a automaÃ§Ã£o de animaÃ§Ãµes.

## 3. Arquitetura e Componentes

A arquitetura do projeto Ã© projetada para ser **100% local**, leve e baseada em **Docker**, aderindo fortemente Ã s prÃ¡ticas de **DataOps** e **Infraestrutura como CÃ³digo (IaC)**.

### Fluxo de Dados

1.  **IngestÃ£o de VÃ­deos:** O usuÃ¡rio coloca vÃ­deos `.mp4` na pasta `videos_input/`.
2.  **Processamento no ContÃªiner:** O pipeline Docker orquestra a execuÃ§Ã£o de um script Python.
3.  **ExtraÃ§Ã£o de Keypoints (IA):** A biblioteca MediaPipe processa cada frame do vÃ­deo para detectar e extrair 33 keypoints de pose.
4.  **Armazenamento Bruto:** Os keypoints extraÃ­dos sÃ£o salvos em arquivos JSON individuais (um por vÃ­deo) na pasta `keypoints_output/`.
5.  **TransformaÃ§Ã£o e Carga:** O script utiliza `Pandas` para achatar e estruturar esses dados JSON.
6.  **Armazenamento Estruturado:** Os dados tabulares dos keypoints sÃ£o carregados em um banco de dados SQLite (`poses.db`) para consultas analÃ­ticas.

### Componentes Chave e Justificativas

*   **Docker / Docker Compose:**
    *   **Justificativa:** Essenciais para containerizar a aplicaÃ§Ã£o. O `Dockerfile` define um ambiente isolado com todas as dependÃªncias (Python, OpenCV, MediaPipe), garantindo que o pipeline seja **100% reproduzÃ­vel** em qualquer mÃ¡quina que tenha Docker instalado. O `docker-compose.yml` orquestra o build da imagem e a execuÃ§Ã£o do contÃªiner, simplificando o setup.
*   **MediaPipe (Google):**
    *   **Justificativa:** Uma poderosa biblioteca de Machine Learning para visÃ£o computacional, escolhida por sua capacidade de extrair de forma eficiente e precisa os 33 keypoints de pose humana em tempo quase real, diretamente dos frames do vÃ­deo.
*   **OpenCV (Open Source Computer Vision Library):**
    *   **Justificativa:** Fundamental para o processamento de vÃ­deo. O pacote `opencv-python-headless` Ã© utilizado porque fornece todas as funcionalidades de processamento de imagem e vÃ­deo necessÃ¡rias sem a dependÃªncia de interfaces grÃ¡ficas, o que Ã© ideal para ambientes de servidor ou contÃªineres Docker.
*   **Python (Script ETL `pipeline/__main__.py`):**
    *   **Justificativa:** A linguagem de programaÃ§Ã£o principal para orquestrar todo o pipeline. O script realiza as etapas de ExtraÃ§Ã£o (ler vÃ­deo, aplicar MediaPipe), TransformaÃ§Ã£o (com `Pandas` para estruturar os dados JSON aninhados em um formato tabular plano) e Carga (salvar no banco SQLite).
*   **Pandas:**
    *   **Justificativa:** Uma biblioteca de anÃ¡lise de dados em Python indispensÃ¡vel para a fase de TransformaÃ§Ã£o. Permite manipular e achatar os dados JSON complexos e aninhados gerados pelo MediaPipe em um formato tabular limpo e facilmente consumÃ­vel pelo SQLite.
*   **SQLite:**
    *   **Justificativa:** Um banco de dados relacional leve e serverless, escolhido como nosso "Data Mart" local. Ã‰ ideal para este projeto por nÃ£o requerer um servidor de banco de dados separado, sendo fÃ¡cil de gerenciar dentro do ambiente containerizado e perfeito para armazenar dados estruturados de keypoints para anÃ¡lises subsequentes.
*   **Volumes Docker:**
    *   **Justificativa:** Cruciais para separar o cÃ³digo do contÃªiner dos dados. Permitem que as pastas `videos_input/`, `keypoints_output/` e `database/` no sistema de arquivos do host sejam mapeadas para dentro do contÃªiner. Isso garante que os dados de entrada, os keypoints brutos e o banco de dados persistam mesmo apÃ³s o contÃªiner ser destruÃ­do, alÃ©m de facilitar a adiÃ§Ã£o de novos vÃ­deos sem reconstruir a imagem Docker.

## 4. Estrutura de DiretÃ³rios do Projeto
```
.
â”œâ”€â”€ database
â”‚Â Â  â””â”€â”€ poses.db
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ keypoints_output
â”‚Â Â  â”œâ”€â”€ movimento1.mp4.json
â”‚Â Â  â”œâ”€â”€ movimento2.mp4.json
â”‚Â Â  â””â”€â”€ movimento3.mp4.json
â”œâ”€â”€ pipeline
â”‚Â Â  â””â”€â”€ __main__.py
â”œâ”€â”€ projeto-pose.md
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ venv
â”‚Â Â  â”œâ”€â”€ bin
â”‚Â Â  â”œâ”€â”€ include
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ lib64 -> lib
â”‚Â Â  â””â”€â”€ pyvenv.cfg
â””â”€â”€ videos_input
    â”œâ”€â”€ movimento1.mp4
    â”œâ”€â”€ movimento2.mp4
    â””â”€â”€ movimento3.mp4

10 directories, 14 files
```

## 5. PrÃ©-requisitos

Para executar este projeto, vocÃª precisarÃ¡ ter instalado em sua mÃ¡quina:

*   **Docker:** Para a construÃ§Ã£o e gerenciamento dos contÃªineres. [Guia de InstalaÃ§Ã£o do Docker](https://docs.docker.com/get-docker/)
*   **Docker Compose:** Para orquestrar o serviÃ§o do pipeline. Geralmente vem incluÃ­do na instalaÃ§Ã£o do Docker Desktop.

## 6. Como Executar o Projeto

A execuÃ§Ã£o do pipeline Ã© **totalmente containerizada** via Docker para garantir um ambiente consistente e reproduzÃ­vel. Embora um ambiente virtual (`venv`) seja fornecido para desenvolvimento local e gerenciamento de dependÃªncias, o mÃ©todo de execuÃ§Ã£o principal e recomendado para o pipeline Ã© atravÃ©s do Docker.

Siga os passos abaixo:

1.  **Prepare os VÃ­deos de Entrada:**
    *   Certifique-se de ter um ou mais arquivos de vÃ­deo no formato `.mp4` na pasta `videos_input/`. Por exemplo, `movimento1.mp4`. Estes serÃ£o os vÃ­deos que o pipeline irÃ¡ processar.

2.  **Abra o Terminal:**
    *   Navegue atÃ© o diretÃ³rio raiz do projeto no seu terminal. Este Ã© o diretÃ³rio que contÃ©m os arquivos `docker-compose.yml` e `Dockerfile`.

3.  **Execute o Pipeline com Docker Compose:**
    *   Execute o comando a seguir para construir a imagem Docker (se ainda nÃ£o tiver sido construÃ­da ou se houver alteraÃ§Ãµes) e iniciar o serviÃ§o do pipeline:

    ```bash
    docker-compose up --build
    ```
    *   **ExplicaÃ§Ã£o do comando:**
        *   `docker-compose up`: Inicia os serviÃ§os definidos no `docker-compose.yml`.
        *   `--build`: Garante que a imagem Docker seja reconstruÃ­da a partir do `Dockerfile` antes de iniciar o contÃªiner. Isso Ã© importante para garantir que todas as dependÃªncias estejam atualizadas e que o ambiente esteja conforme definido.

4.  **Acompanhe o Processamento:**
    *   VocÃª verÃ¡ a saÃ­da do log do pipeline no terminal, indicando o progresso da anÃ¡lise de cada vÃ­deo.

## 7. SaÃ­das e Resultados

ApÃ³s a execuÃ§Ã£o bem-sucedida do comando `docker-compose up --build`, vocÃª encontrarÃ¡ os seguintes resultados no seu sistema de arquivos local, devido ao uso dos volumes Docker:

*   **Keypoints Brutos (JSON):**
    *   Na pasta `keypoints_output/`, vocÃª encontrarÃ¡ um arquivo JSON para cada vÃ­deo processado (ex: `movimento1.mp4.json`). Estes arquivos contÃªm os keypoints brutos extraÃ­dos pelo MediaPipe, frame a frame.
*   **Banco de Dados Estruturado (SQLite):**
    *   Na pasta `database/`, o arquivo `poses.db` serÃ¡ criado ou atualizado. Este banco de dados contÃ©m os keypoints estruturados e achatados em tabelas, prontos para serem consultados ou integrados com outras ferramentas.

## 8. Tecnologias Utilizadas

*   **Python ğŸ:** Linguagem de programaÃ§Ã£o principal.
*   **MediaPipe âœ¨:** Biblioteca de IA para detecÃ§Ã£o de pose.
*   **OpenCV ğŸ¥:** Biblioteca para processamento de vÃ­deo (`opencv-python-headless`).
*   **Pandas ğŸ¼:** Biblioteca para manipulaÃ§Ã£o e estruturaÃ§Ã£o de dados.
*   **SQLite ğŸ—„ï¸:** Banco de dados relacional local.
*   **Docker ï¿½ï¿½:** Plataforma de containerizaÃ§Ã£o.
*   **Docker Compose ğŸš€:** Ferramenta para orquestraÃ§Ã£o de contÃªineres multi-serviÃ§os.

## 9. PrÃ³ximos Passos e Melhorias Futuras

Este projeto serve como uma base robusta e pode ser expandido de diversas maneiras:

*   **IntegraÃ§Ã£o com Blender:** Desenvolver scripts em Python para o Blender que leiam os arquivos JSON ou consultem o `poses.db` para automatizar a animaÃ§Ã£o de modelos 3D.
*   **IntegraÃ§Ã£o com Ferramentas de BI:** Conectar o `poses.db` a ferramentas como Power BI, Tableau ou Grafana para criar dashboards de anÃ¡lise de movimento.
*   **ServiÃ§o Web:** Criar uma API Flask/FastAPI para expor a funcionalidade de anÃ¡lise de vÃ­deos como um serviÃ§o.
*   **NotificaÃ§Ãµes/Alertas:** Adicionar um sistema de notificaÃ§Ã£o para quando um vÃ­deo for processado ou quando certas condiÃ§Ãµes de movimento forem detectadas.
*   **ImplantaÃ§Ã£o em Nuvem:** Migrar o pipeline para um ambiente de nuvem (AWS Lambda, Google Cloud Run, Azure Container Instances) para escalabilidade e processamento distribuÃ­do.
*   **OtimizaÃ§Ã£o de Performance:** Implementar processamento paralelo para vÃ­deos ou otimizar as operaÃ§Ãµes do MediaPipe.

## 10. Autores

Elton M de Lima

## 11. LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT. Consulte o arquivo `LICENSE` para mais detalhes.