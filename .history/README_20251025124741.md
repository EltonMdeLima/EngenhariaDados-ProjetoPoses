# Projeto de Engenharia de Dados: Pipeline DataOps para AnÃ¡lise de Poses ðŸ¤–ðŸ“ŠðŸŽ¥

![Conceito de Imagem de Alto NÃ­vel](https://i.imgur.com/your_image_placeholder.png) 
*Substitua este placeholder com um link para a imagem conceitual descrita acima, se for criada.*

Este projeto foi desenvolvido como parte das atividades do curso de **Especialista em DevOps**, com um foco em **Engenharia de Dados**. Ele exemplifica a construÃ§Ã£o de um pipeline, automatizado e containerizado para a anÃ¡lise e estruturaÃ§Ã£o de movimentos humanos a partir de vÃ­deos.

## 1. VisÃ£o Geral do Projeto

A anÃ¡lise de movimentos humanos, como esportes (otimizaÃ§Ã£o de performance), fisioterapia (reabilitaÃ§Ã£o e acompanhamento), e animaÃ§Ã£o 3D (automaÃ§Ã£o da criaÃ§Ã£o de personagens). Tradicionalmente, a extraÃ§Ã£o de **pontos-chave (keypoints)** que definem a pose de uma pessoa em vÃ­deos Ã© um processo complexo e trabalhoso, exigindo um roupa especial com sensores para capturar movimentos, propenso a erros, demorado e que resulta em dados nÃ£o estruturados, dificultando anÃ¡lises em escala e automaÃ§Ã£o.

Este projeto propÃµe uma soluÃ§Ã£o para esse desafio. A construÃ§Ã£o de pipeline de dados que automatiza a ingestÃ£o de vÃ­deos, a extraÃ§Ã£o de keypoints atravÃ©s de inteligÃªncia artificial, a transformaÃ§Ã£o desses dados em um formato estruturado e o armazenamento em um banco de dados relacional local (SQLite). O tratamento desses dados e a preparaÃ§Ã£o dos keypoints limpos e disponibilizados em arquivos JSON, prontos para integraÃ§Ã£o com ferramentas de modelagem 3D como o Blender, que suportam scripts Python para automaÃ§Ã£o de animaÃ§Ãµes.

## 2. Objetivos do Projeto

O principal objetivo Ã© demonstrar a aplicaÃ§Ã£o de princÃ­pios de Engenharia de Dados e DevOps na criaÃ§Ã£o de um sistema eficiente e reproduzÃ­vel para anÃ¡lise de movimentos. Os objetivos especÃ­ficos incluem:

*   **AutomaÃ§Ã£o da ExtraÃ§Ã£o:** Automatizar a detecÃ§Ã£o e extraÃ§Ã£o de 33 keypoints de pose humana por frame de vÃ­deos de entrada.
*   **EstruturaÃ§Ã£o de Dados:** Transformar os dados semi-estruturados (JSON) gerados pela IA em um formato tabular otimizado para anÃ¡lise.
*   **Armazenamento Eficiente:** Persistir os dados brutos (JSON) e estruturados (SQLite) de forma organizada.
*   **ContainerizaÃ§Ã£o:** Envelopar todo o ambiente e pipeline em contÃªineres Docker, garantindo portabilidade e reprodutibilidade.
*   **PrÃ¡ticas DataOps/DevOps:** Implementar Infraestrutura como CÃ³digo (IaC) e um fluxo de trabalho que promova a colaboraÃ§Ã£o e a entrega contÃ­nua.
*   **PreparaÃ§Ã£o para AnimaÃ§Ã£o 3D:** Gerar dados em um formato que possa ser facilmente consumido por ferramentas de modelagem 3D, facilitando a automaÃ§Ã£o de animaÃ§Ãµes.

## 3. Arquitetura e Componentes

A arquitetura do projeto Ã© projetada para ser **100% local**, leve e baseada em **Docker**, aderindo fortemente Ã s prÃ¡ticas de **DataOps** e **Infraestrutura como CÃ³digo (IaC)**.

### Fluxo de Dados

1.  **IngestÃ£o de VÃ­deos:** O usuÃ¡rio coloca vÃ­deos `.mp4` na pasta `videos_input/`.
2.  **Processamento no ContÃªiner:** O pipeline Docker orquestra a execuÃ§Ã£o de um script Python.
3.  **ExtraÃ§Ã£o de Keypoints (IA):** A biblioteca MediaPipe processa cada frame do vÃ­deo para detectar e extrair 33 keypoints de pose.
4.  **Armazenamento Bruto:** Os keypoints extraÃ­dos sÃ£o salvos em arquivos JSON individuais (um por vÃ­deo) na pasta `keypoints_output/`.
5.  **TransformaÃ§Ã£o e Carga:** O script utiliza `Pandas` para achatar e estruturar esses dados JSON.
6.  **Armazenamento Estruturado:** Os dados tabulares dos keypoints sÃ£o carregados em um banco de dados SQLite (`poses.db`) para consultas analÃ­ticas.

### Componentes Chave e Justificativas

*   **Docker / Docker Compose:**
    *   **Justificativa:** Essenciais para containerizar a aplicaÃ§Ã£o. O `Dockerfile` define um ambiente isolado com todas as dependÃªncias (Python, OpenCV, MediaPipe), garantindo que o pipeline seja **100% reproduzÃ­vel** em qualquer mÃ¡quina que tenha Docker instalado. O `docker-compose.yml` orquestra o build da imagem e a execuÃ§Ã£o do contÃªiner, simplificando o setup.
*   **MediaPipe (Google):**
    *   **Justificativa:** Uma poderosa biblioteca de Machine Learning para visÃ£o computacional, escolhida por sua capacidade de extrair de forma eficiente e precisa os 33 keypoints de pose humana em tempo quase real, diretamente dos frames do vÃ­deo.
*   **OpenCV (Open Source Computer Vision Library):**
    *   **Justificativa:** Fundamental para o processamento de vÃ­deo. O pacote `opencv-python-headless` Ã© utilizado porque fornece todas as funcionalidades de processamento de imagem e vÃ­deo necessÃ¡rias sem a dependÃªncia de interfaces grÃ¡ficas, o que Ã© ideal para ambientes de servidor ou contÃªineres Docker.
*   **Python (Script ETL `pipeline/__main__.py`):**
    *   **Justificativa:** A linguagem de programaÃ§Ã£o principal para orquestrar todo o pipeline. O script realiza as etapas de ExtraÃ§Ã£o (ler vÃ­deo, aplicar MediaPipe), TransformaÃ§Ã£o (com `Pandas` para estruturar os dados JSON aninhados em um formato tabular plano) e Carga (salvar no banco SQLite).
*   **Pandas:**
    *   **Justificativa:** Uma biblioteca de anÃ¡lise de dados em Python indispensÃ¡vel para a fase de TransformaÃ§Ã£o. Permite manipular e achatar os dados JSON complexos e aninhados gerados pelo MediaPipe em um formato tabular limpo e facilmente consumÃ­vel pelo SQLite.
*   **SQLite:**
    *   **Justificativa:** Um banco de dados relacional leve e serverless, escolhido como nosso "Data Mart" local. Ã‰ ideal para este projeto por nÃ£o requerer um servidor de banco de dados separado, sendo fÃ¡cil de gerenciar dentro do ambiente containerizado e perfeito para armazenar dados estruturados de keypoints para anÃ¡lises subsequentes.
*   **Volumes Docker:**
    *   **Justificativa:** Cruciais para separar o cÃ³digo do contÃªiner dos dados. Permitem que as pastas `videos_input/`, `keypoints_output/` e `database/` no sistema de arquivos do host sejam mapeadas para dentro do contÃªiner. Isso garante que os dados de entrada, os keypoints brutos e o banco de dados persistam mesmo apÃ³s o contÃªiner ser destruÃ­do, alÃ©m de facilitar a adiÃ§Ã£o de novos vÃ­deos sem reconstruir a imagem Docker.

## 4. Estrutura de DiretÃ³rios do Projeto
```
.
â”œâ”€â”€ database
â”‚Â Â  â””â”€â”€ poses.db
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ keypoints_output
â”‚Â Â  â”œâ”€â”€ movimento1.mp4.json
â”‚Â Â  â”œâ”€â”€ movimento2.mp4.json
â”‚Â Â  â””â”€â”€ movimento3.mp4.json
â”œâ”€â”€ pipeline
â”‚Â Â  â””â”€â”€ __main__.py
â”œâ”€â”€ projeto-pose.md
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ venv
â”‚Â Â  â”œâ”€â”€ bin
â”‚Â Â  â”œâ”€â”€ include
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ lib64 -> lib
â”‚Â Â  â””â”€â”€ pyvenv.cfg
â””â”€â”€ videos_input
    â”œâ”€â”€ movimento1.mp4
    â”œâ”€â”€ movimento2.mp4
    â””â”€â”€ movimento3.mp4

10 directories, 14 files
```