# Projeto de Engenharia de Dados: Pipeline DataOps para An√°lise de Poses ü§ñüìäüé•

![Conceito de Imagem de Alto N√≠vel](https://i.imgur.com/your_image_placeholder.png) 
*Substitua este placeholder com um link para a imagem conceitual descrita acima, se for criada.*

Este projeto foi desenvolvido como parte das atividades do curso de **Especialista em DevOps**, com um foco em **Engenharia de Dados**. Ele exemplifica a constru√ß√£o de um pipeline, automatizado e containerizado para a an√°lise e estrutura√ß√£o de movimentos humanos a partir de v√≠deos.

## 1. Vis√£o Geral do Projeto

A an√°lise de movimentos humanos, como esportes (otimiza√ß√£o de performance), fisioterapia (reabilita√ß√£o e acompanhamento), e anima√ß√£o 3D (automa√ß√£o da cria√ß√£o de personagens). Tradicionalmente, a extra√ß√£o de **pontos-chave (keypoints)** que definem a pose de uma pessoa em v√≠deos √© um processo complexo e trabalhoso, exigindo um roupa especial com sensores para capturar movimentos, propenso a erros, demorado e que resulta em dados n√£o estruturados, dificultando an√°lises em escala e automa√ß√£o.

Este projeto prop√µe uma solu√ß√£o para esse desafio. A constru√ß√£o de pipeline de dados que automatiza a ingest√£o de v√≠deos, a extra√ß√£o de keypoints atrav√©s de intelig√™ncia artificial, a transforma√ß√£o desses dados em um formato estruturado e o armazenamento em um banco de dados relacional local (SQLite). O tratamento desses dados e a prepara√ß√£o dos keypoints limpos e disponibilizados em arquivos JSON, prontos para integra√ß√£o com ferramentas de modelagem 3D como o Blender, que suportam scripts Python para automa√ß√£o de anima√ß√µes.

## 2. Objetivos do Projeto

O principal objetivo √© demonstrar a aplica√ß√£o de princ√≠pios de Engenharia de Dados e DevOps na cria√ß√£o de um sistema eficiente e reproduz√≠vel para an√°lise de movimentos. Os objetivos espec√≠ficos incluem:

*   **Automa√ß√£o da Extra√ß√£o:** Automatizar a detec√ß√£o e extra√ß√£o de 33 keypoints de pose humana por frame de v√≠deos de entrada.
*   **Estrutura√ß√£o de Dados:** Transformar os dados semi-estruturados (JSON) gerados pela IA em um formato tabular otimizado para an√°lise.
*   **Armazenamento Eficiente:** Persistir os dados brutos (JSON) e estruturados (SQLite) de forma organizada.
*   **Containeriza√ß√£o:** Envelopar todo o ambiente e pipeline em cont√™ineres Docker, garantindo portabilidade e reprodutibilidade.
*   **Pr√°ticas DataOps/DevOps:** Implementar Infraestrutura como C√≥digo (IaC) e um fluxo de trabalho que promova a colabora√ß√£o e a entrega cont√≠nua.
*   **Prepara√ß√£o para Anima√ß√£o 3D:** Gerar dados em um formato que possa ser facilmente consumido por ferramentas de modelagem 3D, facilitando a automa√ß√£o de anima√ß√µes.

## 3. Arquitetura e Componentes

A arquitetura do projeto √© projetada para ser **100% local**, leve e baseada em **Docker**, aderindo fortemente √†s pr√°ticas de **DataOps** e **Infraestrutura como C√≥digo (IaC)**.

### Fluxo de Dados

1.  **Ingest√£o de V√≠deos:** O usu√°rio coloca v√≠deos `.mp4` na pasta `videos_input/`.
2.  **Processamento no Cont√™iner:** O pipeline Docker orquestra a execu√ß√£o de um script Python.
3.  **Extra√ß√£o de Keypoints (IA):** A biblioteca MediaPipe processa cada frame do v√≠deo para detectar e extrair 33 keypoints de pose.
4.  **Armazenamento Bruto:** Os keypoints extra√≠dos s√£o salvos em arquivos JSON individuais (um por v√≠deo) na pasta `keypoints_output/`.
5.  **Transforma√ß√£o e Carga:** O script utiliza `Pandas` para achatar e estruturar esses dados JSON.
6.  **Armazenamento Estruturado:** Os dados tabulares dos keypoints s√£o carregados em um banco de dados SQLite (`poses.db`) para consultas anal√≠ticas.

### Componentes Chave e Justificativas

*   **Docker / Docker Compose:**
    *   **Justificativa:** Essenciais para containerizar a aplica√ß√£o. O `Dockerfile` define um ambiente isolado com todas as depend√™ncias (Python, OpenCV, MediaPipe), garantindo que o pipeline seja **100% reproduz√≠vel** em qualquer m√°quina que tenha Docker instalado. O `docker-compose.yml` orquestra o build da imagem e a execu√ß√£o do cont√™iner, simplificando o setup.
*   **MediaPipe (Google):**
    *   **Justificativa:** Uma poderosa biblioteca de Machine Learning para vis√£o computacional, escolhida por sua capacidade de extrair de forma eficiente e precisa os 33 keypoints de pose humana em tempo quase real, diretamente dos frames do v√≠deo.
*   **OpenCV (Open Source Computer Vision Library):**
    *   **Justificativa:** Fundamental para o processamento de v√≠deo. O pacote `opencv-python-headless` √© utilizado porque fornece todas as funcionalidades de processamento de imagem e v√≠deo necess√°rias sem a depend√™ncia de interfaces gr√°ficas, o que √© ideal para ambientes de servidor ou cont√™ineres Docker.
*   **Python (Script ETL `pipeline/__main__.py`):**
    *   **Justificativa:** A linguagem de programa√ß√£o principal para orquestrar todo o pipeline. O script realiza as etapas de Extra√ß√£o (ler v√≠deo, aplicar MediaPipe), Transforma√ß√£o (com `Pandas` para estruturar os dados JSON aninhados em um formato tabular plano) e Carga (salvar no banco SQLite).
*   **Pandas:**
    *   **Justificativa:** Uma biblioteca de an√°lise de dados em Python indispens√°vel para a fase de Transforma√ß√£o. Permite manipular e achatar os dados JSON complexos e aninhados gerados pelo MediaPipe em um formato tabular limpo e facilmente consum√≠vel pelo SQLite.
*   **SQLite:**
    *   **Justificativa:** Um banco de dados relacional leve e serverless, escolhido como nosso "Data Mart" local. √â ideal para este projeto por n√£o requerer um servidor de banco de dados separado, sendo f√°cil de gerenciar dentro do ambiente containerizado e perfeito para armazenar dados estruturados de keypoints para an√°lises subsequentes.
*   **Volumes Docker:**
    *   **Justificativa:** Cruciais para separar o c√≥digo do cont√™iner dos dados. Permitem que as pastas `videos_input/`, `keypoints_output/` e `database/` no sistema de arquivos do host sejam mapeadas para dentro do cont√™iner. Isso garante que os dados de entrada, os keypoints brutos e o banco de dados persistam mesmo ap√≥s o cont√™iner ser destru√≠do, al√©m de facilitar a adi√ß√£o de novos v√≠deos sem reconstruir a imagem Docker.

## 4. Estrutura de Diret√≥rios do Projeto
```
.
‚îú‚îÄ‚îÄ database
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ poses.db
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ keypoints_output
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ movimento1.mp4.json
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ movimento2.mp4.json
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ movimento3.mp4.json
‚îú‚îÄ‚îÄ pipeline
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ __main__.py
‚îú‚îÄ‚îÄ projeto-pose.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ venv
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ bin
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ include
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lib
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lib64 -> lib
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ pyvenv.cfg
‚îî‚îÄ‚îÄ videos_input
    ‚îú‚îÄ‚îÄ movimento1.mp4
    ‚îú‚îÄ‚îÄ movimento2.mp4
    ‚îî‚îÄ‚îÄ movimento3.mp4

10 directories, 14 files
```

## 5. Pr√©-requisitos

Para executar este projeto, voc√™ precisar√° ter instalado em sua m√°quina:

*   **Docker:** Para a constru√ß√£o e gerenciamento dos cont√™ineres. [Guia de Instala√ß√£o do Docker](https://docs.docker.com/get-docker/)
*   **Docker Compose:** Para orquestrar o servi√ßo do pipeline. Geralmente vem inclu√≠do na instala√ß√£o do Docker Desktop.

## 6. Como Executar o Projeto

A execu√ß√£o do pipeline √© **totalmente containerizada** via Docker para garantir um ambiente consistente e reproduz√≠vel. Embora um ambiente virtual (`venv`) seja fornecido para desenvolvimento local e gerenciamento de depend√™ncias, o m√©todo de execu√ß√£o principal e recomendado para o pipeline √© atrav√©s do Docker.

Siga os passos abaixo:

1.  **Prepare os V√≠deos de Entrada:**
    *   Certifique-se de ter um ou mais arquivos de v√≠deo no formato `.mp4` na pasta `videos_input/`. Por exemplo, `movimento1.mp4`. Estes ser√£o os v√≠deos que o pipeline ir√° processar.

2.  **Abra o Terminal:**
    *   Navegue at√© o diret√≥rio raiz do projeto no seu terminal. Este √© o diret√≥rio que cont√©m os arquivos `docker-compose.yml` e `Dockerfile`.

3.  **Execute o Pipeline com Docker Compose:**
    *   Execute o comando a seguir para construir a imagem Docker (se ainda n√£o tiver sido constru√≠da ou se houver altera√ß√µes) e iniciar o servi√ßo do pipeline:

    ```bash
    docker-compose up --build
    ```
    *   **Explica√ß√£o do comando:**
        *   `docker-compose up`: Inicia os servi√ßos definidos no `docker-compose.yml`.
        *   `--build`: Garante que a imagem Docker seja reconstru√≠da a partir do `Dockerfile` antes de iniciar o cont√™iner. Isso √© importante para garantir que todas as depend√™ncias estejam atualizadas e que o ambiente esteja conforme definido.

4.  **Acompanhe o Processamento:**
    *   Voc√™ ver√° a sa√≠da do log do pipeline no terminal, indicando o progresso da an√°lise de cada v√≠deo.

## 7. Sa√≠das e Resultados

Ap√≥s a execu√ß√£o bem-sucedida do comando `docker-compose up --build`, voc√™ encontrar√° os seguintes resultados no seu sistema de arquivos local, devido ao uso dos volumes Docker:

*   **Keypoints Brutos (JSON):**
    *   Na pasta `keypoints_output/`, voc√™ encontrar√° um arquivo JSON para cada v√≠deo processado (ex: `movimento1.mp4.json`). Estes arquivos cont√™m os keypoints brutos extra√≠dos pelo MediaPipe, frame a frame.
*   **Banco de Dados Estruturado (SQLite):**
    *   Na pasta `database/`, o arquivo `poses.db` ser√° criado ou atualizado. Este banco de dados cont√©m os keypoints estruturados e achatados em tabelas, prontos para serem consultados ou integrados com outras ferramentas.

## 8. Tecnologias Utilizadas

*   **Python:** Linguagem de programa√ß√£o principal.
*   **MediaPipe:** Biblioteca de IA para detec√ß√£o de pose.
*   **OpenCV:** Biblioteca para processamento de v√≠deo (`opencv-python-headless`).
*   **Pandas:** Biblioteca para manipula√ß√£o e estrutura√ß√£o de dados.
*   **SQLite:** Banco de dados relacional local.
*   **Docker:** Plataforma de containeriza√ß√£o.
*   **Docker Compose:** Ferramenta para orquestra√ß√£o de cont√™ineres multi-servi√ßos.

## 9. Pr√≥ximos Passos e Melhorias Futuras

Este projeto serve como uma base robusta e pode ser expandido de diversas maneiras:

*   **Integra√ß√£o com Blender:** Desenvolver scripts em Python para o Blender que leiam os arquivos JSON ou consultem o `poses.db` para automatizar a anima√ß√£o de modelos 3D.
*   **Integra√ß√£o com Ferramentas de BI:** Conectar o `poses.db` a ferramentas como Power BI, Tableau ou Grafana para criar dashboards de an√°lise de movimento.
*   **Servi√ßo Web:** Criar uma API Flask/FastAPI para expor a funcionalidade de an√°lise de v√≠deos como um servi√ßo.
*   **Notifica√ß√µes/Alertas:** Adicionar um sistema de notifica√ß√£o para quando um v√≠deo for processado ou quando certas condi√ß√µes de movimento forem detectadas.
*   **Implanta√ß√£o em Nuvem:** Migrar o pipeline para um ambiente de nuvem (AWS Lambda, Google Cloud Run, Azure Container Instances) para escalabilidade e processamento distribu√≠do.
*   **Otimiza√ß√£o de Performance:** Implementar processamento paralelo para v√≠deos ou otimizar as opera√ß√µes do MediaPipe.

## 10. Autores

*   Elton Marcelino de Lima

## 11. Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT. Consulte o arquivo `LICENSE` para mais detalhes.