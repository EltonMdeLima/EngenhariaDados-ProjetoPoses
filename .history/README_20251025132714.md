# Projeto de Engenharia de Dados: Pipeline DataOps para Análise de Poses 🤖📊🎥

![Conceito de Imagem de Alto Nível](https://i.imgur.com/your_image_placeholder.png) 
*Substitua este placeholder com um link para a imagem conceitual descrita acima, se for criada.*

Este projeto foi desenvolvido como parte das atividades do curso de **Especialista em DevOps**, com um foco em **Engenharia de Dados**. Ele exemplifica a construção de um pipeline, automatizado e containerizado para a análise e estruturação de movimentos humanos a partir de vídeos.

## 1. Visão Geral do Projeto

A análise de movimentos humanos, como esportes (otimização de performance), fisioterapia (reabilitação e acompanhamento), e animação 3D (automação da criação de personagens). Tradicionalmente, a extração de **pontos-chave (keypoints)** que definem a pose de uma pessoa em vídeos é um processo complexo e trabalhoso, exigindo um roupa especial com sensores para capturar movimentos, propenso a erros, demorado e que resulta em dados não estruturados, dificultando análises em escala e automação.

Este projeto propõe uma solução para esse desafio. A construção de pipeline de dados que automatiza a ingestão de vídeos, a extração de keypoints através de inteligência artificial, a transformação desses dados em um formato estruturado e o armazenamento em um banco de dados relacional local (SQLite). O tratamento desses dados e a preparação dos keypoints limpos e disponibilizados em arquivos JSON, prontos para integração com ferramentas de modelagem 3D como o Blender, que suportam scripts Python para automação de animações.

## 2. Objetivos do Projeto

O principal objetivo é demonstrar a aplicação de princípios de Engenharia de Dados e DevOps na criação de um sistema eficiente e reproduzível para análise de movimentos. Os objetivos específicos incluem:

*   **Automação da Extração:** Automatizar a detecção e extração de 33 keypoints de pose humana por frame de vídeos de entrada.
*   **Estruturação de Dados:** Transformar os dados semi-estruturados (JSON) gerados pela IA em um formato tabular otimizado para análise.
*   **Armazenamento Eficiente:** Persistir os dados brutos (JSON) e estruturados (SQLite) de forma organizada.
*   **Containerização:** Envelopar todo o ambiente e pipeline em contêineres Docker, garantindo portabilidade e reprodutibilidade.
*   **Práticas DataOps/DevOps:** Implementar Infraestrutura como Código (IaC) e um fluxo de trabalho que promova a colaboração e a entrega contínua.
*   **Preparação para Animação 3D:** Gerar dados em um formato que possa ser facilmente consumido por ferramentas de modelagem 3D, facilitando a automação de animações.

## 3. Arquitetura e Componentes

A arquitetura do projeto é projetada para ser **100% local**, leve e baseada em **Docker**, aderindo fortemente às práticas de **DataOps** e **Infraestrutura como Código (IaC)**.

### Fluxo de Dados

1.  **Ingestão de Vídeos:** O usuário coloca vídeos `.mp4` na pasta `videos_input/`.
2.  **Processamento no Contêiner:** O pipeline Docker orquestra a execução de um script Python.
3.  **Extração de Keypoints (IA):** A biblioteca MediaPipe processa cada frame do vídeo para detectar e extrair 33 keypoints de pose.
4.  **Armazenamento Bruto:** Os keypoints extraídos são salvos em arquivos JSON individuais (um por vídeo) na pasta `keypoints_output/`.
5.  **Transformação e Carga:** O script utiliza `Pandas` para achatar e estruturar esses dados JSON.
6.  **Armazenamento Estruturado:** Os dados tabulares dos keypoints são carregados em um banco de dados SQLite (`poses.db`) para consultas analíticas.

### Componentes Chave e Justificativas

*   **Docker / Docker Compose:**
    *   **Justificativa:** Essenciais para containerizar a aplicação. O `Dockerfile` define um ambiente isolado com todas as dependências (Python, OpenCV, MediaPipe), garantindo que o pipeline seja **100% reproduzível** em qualquer máquina que tenha Docker instalado. O `docker-compose.yml` orquestra o build da imagem e a execução do contêiner, simplificando o setup.
*   **MediaPipe (Google):**
    *   **Justificativa:** Uma poderosa biblioteca de Machine Learning para visão computacional, escolhida por sua capacidade de extrair de forma eficiente e precisa os 33 keypoints de pose humana em tempo quase real, diretamente dos frames do vídeo.
*   **OpenCV (Open Source Computer Vision Library):**
    *   **Justificativa:** Fundamental para o processamento de vídeo. O pacote `opencv-python-headless` é utilizado porque fornece todas as funcionalidades de processamento de imagem e vídeo necessárias sem a dependência de interfaces gráficas, o que é ideal para ambientes de servidor ou contêineres Docker.
*   **Python (Script ETL `pipeline/__main__.py`):**
    *   **Justificativa:** A linguagem de programação principal para orquestrar todo o pipeline. O script realiza as etapas de Extração (ler vídeo, aplicar MediaPipe), Transformação (com `Pandas` para estruturar os dados JSON aninhados em um formato tabular plano) e Carga (salvar no banco SQLite).
*   **Pandas:**
    *   **Justificativa:** Uma biblioteca de análise de dados em Python indispensável para a fase de Transformação. Permite manipular e achatar os dados JSON complexos e aninhados gerados pelo MediaPipe em um formato tabular limpo e facilmente consumível pelo SQLite.
*   **SQLite:**
    *   **Justificativa:** Um banco de dados relacional leve e serverless, escolhido como nosso "Data Mart" local. É ideal para este projeto por não requerer um servidor de banco de dados separado, sendo fácil de gerenciar dentro do ambiente containerizado e perfeito para armazenar dados estruturados de keypoints para análises subsequentes.
*   **Volumes Docker:**
    *   **Justificativa:** Cruciais para separar o código do contêiner dos dados. Permitem que as pastas `videos_input/`, `keypoints_output/` e `database/` no sistema de arquivos do host sejam mapeadas para dentro do contêiner. Isso garante que os dados de entrada, os keypoints brutos e o banco de dados persistam mesmo após o contêiner ser destruído, além de facilitar a adição de novos vídeos sem reconstruir a imagem Docker.

## 4. Estrutura de Diretórios do Projeto
```
.
├── database
│   └── poses.db
├── docker-compose.yml
├── Dockerfile
├── keypoints_output
│   ├── movimento1.mp4.json
│   ├── movimento2.mp4.json
│   └── movimento3.mp4.json
├── pipeline
│   └── __main__.py
├── projeto-pose.md
├── README.md
├── requirements.txt
├── venv
│   ├── bin
│   ├── include
│   ├── lib
│   ├── lib64 -> lib
│   └── pyvenv.cfg
└── videos_input
    ├── movimento1.mp4
    ├── movimento2.mp4
    └── movimento3.mp4

10 directories, 14 files
```

## 5. Pré-requisitos

Para executar este projeto, você precisará ter instalado em sua máquina:

*   **Docker:** Para a construção e gerenciamento dos contêineres. [Guia de Instalação do Docker](https://docs.docker.com/get-docker/)
*   **Docker Compose:** Para orquestrar o serviço do pipeline. Geralmente vem incluído na instalação do Docker Desktop.

## 6. Como Executar o Projeto

A execução do pipeline é **totalmente containerizada** via Docker para garantir um ambiente consistente e reproduzível. Embora um ambiente virtual (`venv`) seja fornecido para desenvolvimento local e gerenciamento de dependências, o método de execução principal e recomendado para o pipeline é através do Docker.

Siga os passos abaixo:

1.  **Prepare os Vídeos de Entrada:**
    *   Certifique-se de ter um ou mais arquivos de vídeo no formato `.mp4` na pasta `videos_input/`. Por exemplo, `movimento1.mp4`. Estes serão os vídeos que o pipeline irá processar.

2.  **Abra o Terminal:**
    *   Navegue até o diretório raiz do projeto no seu terminal. Este é o diretório que contém os arquivos `docker-compose.yml` e `Dockerfile`.

3.  **Execute o Pipeline com Docker Compose:**
    *   Execute o comando a seguir para construir a imagem Docker (se ainda não tiver sido construída ou se houver alterações) e iniciar o serviço do pipeline:

    ```bash
    docker-compose up --build
    ```
    *   **Explicação do comando:**
        *   `docker-compose up`: Inicia os serviços definidos no `docker-compose.yml`.
        *   `--build`: Garante que a imagem Docker seja reconstruída a partir do `Dockerfile` antes de iniciar o contêiner. Isso é importante para garantir que todas as dependências estejam atualizadas e que o ambiente esteja conforme definido.

4.  **Acompanhe o Processamento:**
    *   Você verá a saída do log do pipeline no terminal, indicando o progresso da análise de cada vídeo.

## 7. Saídas e Resultados

Após a execução bem-sucedida do comando `docker-compose up --build`, você encontrará os seguintes resultados no seu sistema de arquivos local, devido ao uso dos volumes Docker:

*   **Keypoints Brutos (JSON):**
    *   Na pasta `keypoints_output/`, você encontrará um arquivo JSON para cada vídeo processado (ex: `movimento1.mp4.json`). Estes arquivos contêm os keypoints brutos extraídos pelo MediaPipe, frame a frame.
*   **Banco de Dados Estruturado (SQLite):**
    *   Na pasta `database/`, o arquivo `poses.db` será criado ou atualizado. Este banco de dados contém os keypoints estruturados e achatados em tabelas, prontos para serem consultados ou integrados com outras ferramentas.

## 8. Tecnologias Utilizadas

*   **Python:** Linguagem de programação principal.
*   **MediaPipe:** Biblioteca de IA para detecção de pose.
*   **OpenCV:** Biblioteca para processamento de vídeo (`opencv-python-headless`).
*   **Pandas:** Biblioteca para manipulação e estruturação de dados.
*   **SQLite:** Banco de dados relacional local.
*   **Docker:** Plataforma de containerização.
*   **Docker Compose:** Ferramenta para orquestração de contêineres multi-serviços.

## 9. Próximos Passos e Melhorias Futuras

Este projeto serve como uma base robusta e pode ser expandido de diversas maneiras:

*   **Integração com Blender:** Desenvolver scripts em Python para o Blender que leiam os arquivos JSON ou consultem o `poses.db` para automatizar a animação de modelos 3D.
*   **Integração com Ferramentas de BI:** Conectar o `poses.db` a ferramentas como Power BI, Tableau ou Grafana para criar dashboards de análise de movimento.
*   **Serviço Web:** Criar uma API Flask/FastAPI para expor a funcionalidade de análise de vídeos como um serviço.
*   **Notificações/Alertas:** Adicionar um sistema de notificação para quando um vídeo for processado ou quando certas condições de movimento forem detectadas.
*   **Implantação em Nuvem:** Migrar o pipeline para um ambiente de nuvem (AWS Lambda, Google Cloud Run, Azure Container Instances) para escalabilidade e processamento distribuído.
*   **Otimização de Performance:** Implementar processamento paralelo para vídeos ou otimizar as operações do MediaPipe.

## 10. Autores

*   Elton Marcelino de Lima

## 11. Licença

Este projeto está licenciado sob a licença MIT. Consulte o arquivo `LICENSE` para mais detalhes.